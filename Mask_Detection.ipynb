{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cbcea19-8402-46f3-ac7d-5375358ca7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vanshika Mishra\\anaconda3\\lib\\site-packages\\scipy\\__init__.py:138: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.4)\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion} is required for this version of \"\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d38c7b9f-5dd7-44ae-8827-b2208939136f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model= Sequential()\n",
    "model.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Conv2D(32,(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bd26054-ff1b-4e83-8b76-6708557516da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 148, 148, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 74, 74, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 72, 72, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 34, 34, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 17, 17, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9248)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 100)               924900    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 944,393\n",
      "Trainable params: 944,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "733e4fd5-27da-4054-8380-1b7631fd0d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8982315b-54be-4550-a543-65e350d0408e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen=ImageDataGenerator(\n",
    "rescale=1./225,\n",
    "shear_range=0.2,\n",
    "zoom_range=0.2,\n",
    "horizontal_flip=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4fff322-0f4e-44c4-82c4-8919e703c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_datagen=ImageDataGenerator(rescale=1./225)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "715e3b53-74a3-4e43-8c5b-71822589d988",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7395 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set=train_datagen.flow_from_directory(\n",
    "    'train',\n",
    "    target_size=(150,150),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88873a8-e457-48b3-9cc3-50440cf95ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 158 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_set=test_datagen.flow_from_directory(\n",
    "    'test',\n",
    "    target_size=(150,150),\n",
    "    batch_size=16,\n",
    "    class_mode='binary'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539a7baa-dff8-4f15-a96f-756097b4e63f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vanshika Mishra\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py:1972: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "10/10 [==============================] - 6s 543ms/step - loss: 0.3754 - accuracy: 0.7848 - val_loss: 0.2712 - val_accuracy: 0.8544\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 4s 350ms/step - loss: 0.2349 - accuracy: 0.8544 - val_loss: 0.1398 - val_accuracy: 0.8544\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 3s 344ms/step - loss: 0.1633 - accuracy: 0.9177 - val_loss: 0.1018 - val_accuracy: 1.0000\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 3s 324ms/step - loss: 0.1219 - accuracy: 0.9747 - val_loss: 0.0674 - val_accuracy: 0.9937\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 3s 309ms/step - loss: 0.0617 - accuracy: 0.9937 - val_loss: 0.0326 - val_accuracy: 0.9937\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 3s 320ms/step - loss: 0.1559 - accuracy: 0.9241 - val_loss: 0.0817 - val_accuracy: 1.0000\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 4s 363ms/step - loss: 0.1211 - accuracy: 0.9367 - val_loss: 0.0795 - val_accuracy: 1.0000\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 4s 396ms/step - loss: 0.0750 - accuracy: 1.0000 - val_loss: 0.0621 - val_accuracy: 0.9747\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 3s 314ms/step - loss: 0.0409 - accuracy: 0.9937 - val_loss: 0.0075 - val_accuracy: 1.0000\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 3s 318ms/step - loss: 0.0233 - accuracy: 0.9873 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 3s 317ms/step - loss: 0.0361 - accuracy: 0.9937 - val_loss: 0.0105 - val_accuracy: 1.0000\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 3s 338ms/step - loss: 0.0928 - accuracy: 0.9873 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 4s 380ms/step - loss: 0.0427 - accuracy: 0.9810 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.0609 - accuracy: 0.9684 - val_loss: 0.0173 - val_accuracy: 0.9937\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 3s 332ms/step - loss: 0.0970 - accuracy: 0.9684 - val_loss: 0.0044 - val_accuracy: 1.0000\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 3s 346ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 5.3370e-04 - val_accuracy: 1.0000\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 3s 327ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 1.3091e-04 - val_accuracy: 1.0000\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 3s 331ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 4.4378e-04 - val_accuracy: 1.0000\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 3s 340ms/step - loss: 0.0504 - accuracy: 0.9873 - val_loss: 0.0045 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 3s 333ms/step - loss: 0.0753 - accuracy: 0.9747 - val_loss: 0.0182 - val_accuracy: 0.9937\n"
     ]
    }
   ],
   "source": [
    "history=model.fit_generator(\n",
    "training_set,\n",
    "epochs=20,\n",
    "validation_data=test_set,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "119c3fbc-1713-4a79-af50-7f6fc43f12f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: mask_detector\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('mask_detector',history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91524836-992c-463f-8a21-3269ea5755b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "from keras.models import load_model\n",
    "from keras.preprocessing import image \n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "273a94e3-e93f-4ef5-b47f-8b63b8b8c3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mymodel=load_model('mask_detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "199c34fa-de06-4752-b4a2-fc6bab04fa34",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497a1d3b-0e5a-4913-8b6a-eb9c7b9f4a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap=cv2.VideoCapture(0)\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH,1280)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT,720)\n",
    "\n",
    "while cap.isOpened():\n",
    "    s,img=cap.read()\n",
    "    face=face_cascade.detectMultiScale(img,scaleFactor=1.1,minNeighbors =4)\n",
    "    \n",
    "    for(x,y,w,h) in face:\n",
    "        face_img=img[y:y+h,x:x+w]\n",
    "        cv2.imwrite('temp.jpg',face_img)\n",
    "        test_img=image.load_img('temp.jpg',target_size=(150,150,3))\n",
    "        test_img= image.img_to_array(test_img)\n",
    "        test_img=np.expand_dims(test_img,axis=0)\n",
    "        \n",
    "        pred=mymodel.predict(test_img)[0][0]\n",
    "        \n",
    "        if pred==1:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.rectangle(img,(x,y-40),(x+w,y),(0,255,0),-1)\n",
    "            cv2.putText(img,\"No Mask\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "\n",
    "        else:\n",
    "            cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "            cv2.rectangle(img,(x,y-40),(x+w,y),(0,255,0),-1)\n",
    "            cv2.putText(img,\"Mask\",(x,y-10),cv2.FONT_HERSHEY_SIMPLEX,0.8,(255,255,255),2)\n",
    "\n",
    "    cv2.imshow('Image',img)\n",
    "    if cv2.waitKey(1)==ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4cd183d-e662-4bfd-909b-ec3451863836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7b65ba-0270-4392-befb-f6b8e201ce3a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
